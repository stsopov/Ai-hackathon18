source('~/TEMP/AI-hack-gaz/Code/R/*_xgb_ensemble.R')
preds <- xgb.base.list[[1]]
for (i in 2:length(xgb.base.list)) {
preds <- cbind(preds, (xgb.base.list[[i]])
}
pred.base <- data.frame(id = id[test.id], proba = rowSums(preds)/length(seeds))
pred.base$TV <- pred.base$proba / max(pred.base$proba)
submission.name = "xgb_ensemble_ranks"
write.csv(pred.base, paste0("Results/", submission.name, ".csv"), row.names = F,quote = F)
length(xgb.base.list)
load("Data/prepared/xgb-ensemble")
length(xgb.base.list)
preds <- xgb.base.list[[1]]
for (i in 2:length(xgb.base.list)) {
preds <- cbind(preds, (xgb.base.list[[i]]))
}
pred.base <- data.frame(id = id[test.id], proba = rowSums(preds)/length(seeds))
head(pred.base)
n_iter
xgb.base.list[[1]]
head(xgb.base.list[[1]])
preds <- xgb.base.list[[1]]
for (i in 2:length(xgb.base.list)) {
preds <- cbind(preds, rank(xgb.base.list[[i]]))
}
pred.base <- data.frame(id = id[test.id], proba = rowSums(preds)/length(xgb.base.list))
pred.base$proba <- pred.base$proba / max(pred.base$proba)
submission.name = "xgb_ensemble_ranks"
write.csv(pred.base, paste0("Results/", submission.name, ".csv"), row.names = F,quote = F)
preds <- xgb.base.list[[1]]
for (i in 2:length(xgb.base.list)) {
preds <- cbind(preds, (xgb.base.list[[i]]))
}
pred.base <- data.frame(id = id[test.id], proba = rowSums(preds)/length(xgb.base.list))
submission.name = "xgb"
write.csv(pred.base, paste0("Results/", submission.name, ".csv"), row.names = F,quote = F)
head(pred.base)
submission.name = "xgb_ensemble"
write.csv(pred.base, paste0("Results/", submission.name, ".csv"), row.names = F,quote = F)
head(pred.base)
source('~/TEMP/AI-hack-gaz/Code/R/*_xgb_ensemble.R')
getDummyVar <- function(dataset, par, min_freq) {
par.value <- dataset[[par]]
par.value[is.na(par.value)] <- "MISSED"
par_freq <- table(par.value)
popular_pars <- names(par_freq)[par_freq >= min_freq]
par_prep <- dataset[[par]]
par_prep[which(!par_prep %in% popular_pars)] <- "other"
dummyPar <- as.matrix(sparse.model.matrix(~-1 + ., data = data.frame(dummy.par = as.factor(par_prep))))
colnames(dummyPar) <- paste0(par, "__",1:ncol(dummyPar))
dummyPar
}
load("Data/prepared/all_stat")
load("Data/prepared/this_month_stat")
load("Data/prepared/last_year_stat")
all.stat$days_passed_after_first_p <- as.numeric(difftime(all.stat$month,
all.stat$f_date, units = "days"))
all.stat <- merge(all.stat, user.labels, by = c("id", "month"))
all.stat <- all.stat[all.stat$month != '2017-12-01',]
dallFeatures <- all.stat
dummyMonth <- getDummyVar(dallFeatures, "month", 0 )
dallFeatures <- cbind(dallFeatures, dummyMonth)
dummyFMonth <- getDummyVar(dallFeatures, "f_month", 1000 )
dallFeatures <- cbind(dallFeatures, dummyFMonth)
if (F) {
train.miha <- read.csv("Data/prepared/gpn_train_data_last_3_mon_y_v4_with_split_id.csv", stringsAsFactors = F)
test.miha <- read.csv("Data/prepared/gpn_test_data_x_v4.csv", stringsAsFactors = F)
train.miha$month <- ifelse(train.miha$end_time == "1506805200", '2017-09-01',
ifelse(train.miha$end_time == "1509397200", '2017-10-01', '2017-11-01'))
test.miha$month <- ifelse(test.miha$end_time == "1506805200", '2017-09-01', '2017-11-01')
train.miha <- train.miha[, order(colnames(train.miha))]
train.miha$ll <- NULL
train.miha$y <- NULL
test.miha <- test.miha[, order(colnames(test.miha))]
all.miha <- rbind(train.miha, test.miha)
all.miha[,c('y', 'll', 'max_date_purchase', 'end_time', 'min_fp','tt','id_1','id_3','id_2')] <- NULL
all.miha$end_time <- NULL
all.miha[['tt1']]=all.miha[['recency_days']]/all.miha[['mean_period']]
all.miha[['tt2']]=all.miha[['recency_days']]-all.miha[['mean_period']]
all.miha[['tt3']]=all.miha[['current_period']]/all.miha[['mean_period']]
all.miha[['tt4']]=all.miha[['revenue']]*0.04-all.miha[['sum_percent']]
all.miha[['tt5']]=all.miha[['churn']]*all.miha[['recency_days']]
all.miha[['tt6']]=all.miha[['month_churn']]*all.miha[['churn']]
all.miha[['tt7']]=all.miha[['purchases']]*all.miha[['differ_azs']]
all.miha[['tt8']]=all.miha[['last_volume']]/all.miha[['avpu']]
all.miha[['tt9']]=all.miha[['purchases']]/all.miha[['lt']]
colnames(all.miha)[!colnames(all.miha) %in% c("id", "month")] <- paste0(colnames(all.miha)[!colnames(all.miha) %in% c("id", "month")],
"_miha")
dallFeatures <- merge(dallFeatures, all.miha, by = c("id", "month"))
}
dallFeatures <- merge(dallFeatures, this.month.stat, by = c("id", "month"))
dallFeatures <- merge(dallFeatures, last.year.stat, by = c("id", "month"), all.x = T)
dallFeatures[, c("f_month", "next_month", "month_diff",
"last_purchase_date", "f_date")] <- NULL
train.id <- which(dallFeatures$is_test == 0 &
dallFeatures$month %in% c("2017-09-01", "2017-11-01") # &
# dallFeatures$id %in% train_data$id
)
test.id <- which(dallFeatures$is_test == 1 &
dallFeatures$month %in% c("2017-09-01", "2017-11-01"))
TV <- dallFeatures$TV
id <- dallFeatures$id
dallFeatures[, c("id", "month", "is_test", "TV")] <- NULL
dallFeatures$f_1 <- dallFeatures$day_last_purchase + dallFeatures$average_period
dallFeatures[is.na(dallFeatures)] <- 0
dallFeatures$last_code <- NULL
dallFeatures$last_code1 <- NULL
dallFeatures$n_month_was
head(dallFeatures)
getDummyVar <- function(dataset, par, min_freq) {
par.value <- dataset[[par]]
par.value[is.na(par.value)] <- "MISSED"
par_freq <- table(par.value)
popular_pars <- names(par_freq)[par_freq >= min_freq]
par_prep <- dataset[[par]]
par_prep[which(!par_prep %in% popular_pars)] <- "other"
dummyPar <- as.matrix(sparse.model.matrix(~-1 + ., data = data.frame(dummy.par = as.factor(par_prep))))
colnames(dummyPar) <- paste0(par, "__",1:ncol(dummyPar))
dummyPar
}
load("Data/prepared/all_stat")
load("Data/prepared/this_month_stat")
load("Data/prepared/last_year_stat")
all.stat$days_passed_after_first_p <- as.numeric(difftime(all.stat$month,
all.stat$f_date, units = "days"))
all.stat <- merge(all.stat, user.labels, by = c("id", "month"))
all.stat <- all.stat[all.stat$month != '2017-12-01',]
dallFeatures <- all.stat
dummyMonth <- getDummyVar(dallFeatures, "month", 0 )
dallFeatures <- cbind(dallFeatures, dummyMonth)
dummyFMonth <- getDummyVar(dallFeatures, "f_month", 1000 )
dallFeatures <- cbind(dallFeatures, dummyFMonth)
if (F) {
train.miha <- read.csv("Data/prepared/gpn_train_data_last_3_mon_y_v4_with_split_id.csv", stringsAsFactors = F)
test.miha <- read.csv("Data/prepared/gpn_test_data_x_v4.csv", stringsAsFactors = F)
train.miha$month <- ifelse(train.miha$end_time == "1506805200", '2017-09-01',
ifelse(train.miha$end_time == "1509397200", '2017-10-01', '2017-11-01'))
test.miha$month <- ifelse(test.miha$end_time == "1506805200", '2017-09-01', '2017-11-01')
train.miha <- train.miha[, order(colnames(train.miha))]
train.miha$ll <- NULL
train.miha$y <- NULL
test.miha <- test.miha[, order(colnames(test.miha))]
all.miha <- rbind(train.miha, test.miha)
all.miha[,c('y', 'll', 'max_date_purchase', 'end_time', 'min_fp','tt','id_1','id_3','id_2')] <- NULL
all.miha$end_time <- NULL
all.miha[['tt1']]=all.miha[['recency_days']]/all.miha[['mean_period']]
all.miha[['tt2']]=all.miha[['recency_days']]-all.miha[['mean_period']]
all.miha[['tt3']]=all.miha[['current_period']]/all.miha[['mean_period']]
all.miha[['tt4']]=all.miha[['revenue']]*0.04-all.miha[['sum_percent']]
all.miha[['tt5']]=all.miha[['churn']]*all.miha[['recency_days']]
all.miha[['tt6']]=all.miha[['month_churn']]*all.miha[['churn']]
all.miha[['tt7']]=all.miha[['purchases']]*all.miha[['differ_azs']]
all.miha[['tt8']]=all.miha[['last_volume']]/all.miha[['avpu']]
all.miha[['tt9']]=all.miha[['purchases']]/all.miha[['lt']]
colnames(all.miha)[!colnames(all.miha) %in% c("id", "month")] <- paste0(colnames(all.miha)[!colnames(all.miha) %in% c("id", "month")],
"_miha")
dallFeatures <- merge(dallFeatures, all.miha, by = c("id", "month"))
}
dallFeatures <- merge(dallFeatures, this.month.stat, by = c("id", "month"))
dallFeatures <- merge(dallFeatures, last.year.stat, by = c("id", "month"), all.x = T)
dallFeatures[, c("f_month", "next_month", "month_diff",
"last_purchase_date", "f_date")] <- NULL
train.id <- which(dallFeatures$is_test == 0 &
dallFeatures$month %in% c("2017-09-01", "2017-11-01") # &
# dallFeatures$id %in% train_data$id
)
test.id <- which(dallFeatures$is_test == 1 &
dallFeatures$month %in% c("2017-09-01", "2017-11-01"))
TV <- dallFeatures$TV
id <- dallFeatures$id
dallFeatures[, c("id", "month", "is_test", "TV")] <- NULL
dallFeatures$f_1 <- dallFeatures$day_last_purchase + dallFeatures$average_period
dallFeatures[is.na(dallFeatures)] <- 0
dallFeatures$last_code <- NULL
dallFeatures$last_code1 <- NULL
library(h2o)
getROC_AUC = function(probs, true_Y){
probsSort = sort(probs, decreasing = TRUE, index.return = TRUE)
val = unlist(probsSort$x)
idx = unlist(probsSort$ix)
roc_y = true_Y[idx];
stack_x = cumsum(roc_y == 0)/sum(roc_y == 0)
stack_y = cumsum(roc_y == 1)/sum(roc_y == 1)
auc = sum((stack_x[2:length(roc_y)]-stack_x[1:length(roc_y)-1])*stack_y[2:length(roc_y)])
return(list(stack_x=stack_x, stack_y=stack_y, auc=auc))
}
normalize <- function(x)
{
x <- x - min(x)
x / max(x)
}
getDummyVar <- function(dataset, par, min_freq) {
par.value <- dataset[[par]]
par.value[is.na(par.value)] <- "MISSED"
par_freq <- table(par.value)
popular_pars <- names(par_freq)[par_freq >= min_freq]
par_prep <- dataset[[par]]
par_prep[which(!par_prep %in% popular_pars)] <- "other"
dummyPar <- as.matrix(sparse.model.matrix(~-1 + ., data = data.frame(dummy.par = as.factor(par_prep))))
colnames(dummyPar) <- paste0(par, "__",1:ncol(dummyPar))
dummyPar
}
dallFeaturesNN <- dallFeatures[, c("this_month_n_transactions_non_zero_volume", "sd_period"                       ,
"this_month_average_period",                 "this_month_n_transactions"      ,
"min_period" ,                               "day_last_purchase"             ,
"n_transactions"  ,                          "month__1"                     ,
"this_month_q25_period"   ,                  "this_month_min_period"         ,
"f_1"                    ,                   "this_month_sum_volume"         ,
"q75_percent"            ,                   "n_transactions_non_zero_volume",
"this_month_q75_period", "average_period",
"sum_sum_b", "sum_sum_b", "this_month_sd_period")]
dummyDay <- getDummyVar(dallFeaturesNN, "day_last_purchase", 1000 )
dallFeaturesNN <- cbind(dallFeaturesNN, dummyDay)
dummyMonthWas <- getDummyVar(dallFeaturesNN, "n_month_was", 1000 )
dallFeaturesNN <- cbind(dallFeaturesNN, dummyMonthWas)
for (j in 1:ncol(dallFeaturesNN)) {
dallFeaturesNN[[j]] <- normalize(dallFeaturesNN[[j]])
}
getDummyVar <- function(dataset, par, min_freq) {
par.value <- dataset[[par]]
par.value[is.na(par.value)] <- "MISSED"
par_freq <- table(par.value)
popular_pars <- names(par_freq)[par_freq >= min_freq]
par_prep <- dataset[[par]]
par_prep[which(!par_prep %in% popular_pars)] <- "other"
dummyPar <- as.matrix(sparse.model.matrix(~-1 + ., data = data.frame(dummy.par = as.factor(par_prep))))
colnames(dummyPar) <- paste0(par, "__",1:ncol(dummyPar))
dummyPar
}
load("Data/prepared/all_stat")
load("Data/prepared/this_month_stat")
load("Data/prepared/last_year_stat")
all.stat$days_passed_after_first_p <- as.numeric(difftime(all.stat$month,
all.stat$f_date, units = "days"))
all.stat <- merge(all.stat, user.labels, by = c("id", "month"))
all.stat <- all.stat[all.stat$month != '2017-12-01',]
dallFeatures <- all.stat
dummyMonth <- getDummyVar(dallFeatures, "month", 0 )
dallFeatures <- cbind(dallFeatures, dummyMonth)
dummyFMonth <- getDummyVar(dallFeatures, "f_month", 1000 )
dallFeatures <- cbind(dallFeatures, dummyFMonth)
if (F) {
train.miha <- read.csv("Data/prepared/gpn_train_data_last_3_mon_y_v4_with_split_id.csv", stringsAsFactors = F)
test.miha <- read.csv("Data/prepared/gpn_test_data_x_v4.csv", stringsAsFactors = F)
train.miha$month <- ifelse(train.miha$end_time == "1506805200", '2017-09-01',
ifelse(train.miha$end_time == "1509397200", '2017-10-01', '2017-11-01'))
test.miha$month <- ifelse(test.miha$end_time == "1506805200", '2017-09-01', '2017-11-01')
train.miha <- train.miha[, order(colnames(train.miha))]
train.miha$ll <- NULL
train.miha$y <- NULL
test.miha <- test.miha[, order(colnames(test.miha))]
all.miha <- rbind(train.miha, test.miha)
all.miha[,c('y', 'll', 'max_date_purchase', 'end_time', 'min_fp','tt','id_1','id_3','id_2')] <- NULL
all.miha$end_time <- NULL
all.miha[['tt1']]=all.miha[['recency_days']]/all.miha[['mean_period']]
all.miha[['tt2']]=all.miha[['recency_days']]-all.miha[['mean_period']]
all.miha[['tt3']]=all.miha[['current_period']]/all.miha[['mean_period']]
all.miha[['tt4']]=all.miha[['revenue']]*0.04-all.miha[['sum_percent']]
all.miha[['tt5']]=all.miha[['churn']]*all.miha[['recency_days']]
all.miha[['tt6']]=all.miha[['month_churn']]*all.miha[['churn']]
all.miha[['tt7']]=all.miha[['purchases']]*all.miha[['differ_azs']]
all.miha[['tt8']]=all.miha[['last_volume']]/all.miha[['avpu']]
all.miha[['tt9']]=all.miha[['purchases']]/all.miha[['lt']]
colnames(all.miha)[!colnames(all.miha) %in% c("id", "month")] <- paste0(colnames(all.miha)[!colnames(all.miha) %in% c("id", "month")],
"_miha")
dallFeatures <- merge(dallFeatures, all.miha, by = c("id", "month"))
}
dallFeatures <- merge(dallFeatures, this.month.stat, by = c("id", "month"))
dallFeatures <- merge(dallFeatures, last.year.stat, by = c("id", "month"), all.x = T)
dallFeatures[, c("f_month", "next_month", "month_diff",
"last_purchase_date", "f_date")] <- NULL
train.id <- which(dallFeatures$is_test == 0 &
dallFeatures$month %in% c("2017-09-01", "2017-11-01") # &
# dallFeatures$id %in% train_data$id
)
test.id <- which(dallFeatures$is_test == 1 &
dallFeatures$month %in% c("2017-09-01", "2017-11-01"))
TV <- dallFeatures$TV
id <- dallFeatures$id
dallFeatures[, c("id", "month", "is_test", "TV")] <- NULL
dallFeatures$f_1 <- dallFeatures$day_last_purchase + dallFeatures$average_period
dallFeatures[is.na(dallFeatures)] <- 0
dallFeatures$last_code <- NULL
dallFeatures$last_code1 <- NULL
library(h2o)
getROC_AUC = function(probs, true_Y){
probsSort = sort(probs, decreasing = TRUE, index.return = TRUE)
val = unlist(probsSort$x)
idx = unlist(probsSort$ix)
roc_y = true_Y[idx];
stack_x = cumsum(roc_y == 0)/sum(roc_y == 0)
stack_y = cumsum(roc_y == 1)/sum(roc_y == 1)
auc = sum((stack_x[2:length(roc_y)]-stack_x[1:length(roc_y)-1])*stack_y[2:length(roc_y)])
return(list(stack_x=stack_x, stack_y=stack_y, auc=auc))
}
normalize <- function(x)
{
x <- x - min(x)
x / max(x)
}
getDummyVar <- function(dataset, par, min_freq) {
par.value <- dataset[[par]]
par.value[is.na(par.value)] <- "MISSED"
par_freq <- table(par.value)
popular_pars <- names(par_freq)[par_freq >= min_freq]
par_prep <- dataset[[par]]
par_prep[which(!par_prep %in% popular_pars)] <- "other"
dummyPar <- as.matrix(sparse.model.matrix(~-1 + ., data = data.frame(dummy.par = as.factor(par_prep))))
colnames(dummyPar) <- paste0(par, "__",1:ncol(dummyPar))
dummyPar
}
dallFeaturesNN <- dallFeatures[, c("this_month_n_transactions_non_zero_volume", "sd_period"                       ,
"this_month_average_period",                 "this_month_n_transactions"      ,
"min_period" ,                               "day_last_purchase"             ,
"n_transactions"  ,                          "month__1"                     ,
"this_month_q25_period"   ,                  "this_month_min_period"         ,
"f_1"                    ,                   "this_month_sum_volume"         ,
"q75_percent"            ,                   "n_transactions_non_zero_volume",
"this_month_q75_period", "average_period",
"sum_sum_b", "sum_sum_b", "this_month_sd_period")]
dummyDay <- getDummyVar(dallFeaturesNN, "day_last_purchase", 1000 )
dallFeaturesNN <- cbind(dallFeaturesNN, dummyDay)
dummyMonthWas <- getDummyVar(dallFeaturesNN, "n_month_was", 1000 )
dallFeaturesNN <- cbind(dallFeaturesNN, dummyMonthWas)
library(h2o)
getROC_AUC = function(probs, true_Y){
probsSort = sort(probs, decreasing = TRUE, index.return = TRUE)
val = unlist(probsSort$x)
idx = unlist(probsSort$ix)
roc_y = true_Y[idx];
stack_x = cumsum(roc_y == 0)/sum(roc_y == 0)
stack_y = cumsum(roc_y == 1)/sum(roc_y == 1)
auc = sum((stack_x[2:length(roc_y)]-stack_x[1:length(roc_y)-1])*stack_y[2:length(roc_y)])
return(list(stack_x=stack_x, stack_y=stack_y, auc=auc))
}
normalize <- function(x)
{
x <- x - min(x)
x / max(x)
}
getDummyVar <- function(dataset, par, min_freq) {
par.value <- dataset[[par]]
par.value[is.na(par.value)] <- "MISSED"
par_freq <- table(par.value)
popular_pars <- names(par_freq)[par_freq >= min_freq]
par_prep <- dataset[[par]]
par_prep[which(!par_prep %in% popular_pars)] <- "other"
dummyPar <- as.matrix(sparse.model.matrix(~-1 + ., data = data.frame(dummy.par = as.factor(par_prep))))
colnames(dummyPar) <- paste0(par, "__",1:ncol(dummyPar))
dummyPar
}
dallFeaturesNN <- dallFeatures[, c("this_month_n_transactions_non_zero_volume", "sd_period"                       ,
"this_month_average_period",                 "this_month_n_transactions"      ,
"min_period" ,                               "day_last_purchase"             ,
"n_transactions"  ,                          "month__1"                     ,
"this_month_q25_period"   ,                  "this_month_min_period"         ,
"f_1"                    ,                   "this_month_sum_volume"         ,
"q75_percent"            ,                   "n_transactions_non_zero_volume",
"this_month_q75_period", "average_period",
"sum_sum_b", "sum_sum_b", "this_month_sd_period", "n_month_was")]
dummyDay <- getDummyVar(dallFeaturesNN, "day_last_purchase", 1000 )
dallFeaturesNN <- cbind(dallFeaturesNN, dummyDay)
dummyMonthWas <- getDummyVar(dallFeaturesNN, "n_month_was", 1000 )
dallFeaturesNN <- cbind(dallFeaturesNN, dummyMonthWas)
for (j in 1:ncol(dallFeaturesNN)) {
dallFeaturesNN[[j]] <- normalize(dallFeaturesNN[[j]])
}
dim(dallFeaturesNN)
print(seed)
######
# CV #
######
nfolds <- 3
id <- train.id
preds.base.train <- data.frame(predict = rep(0, length(id)), id = id)
for (i in 1:nfolds) {
id.fold <- which((id %% nfolds + 1) != i)
id.cv <- which((id %% nfolds + 1) == i)
train <- data.frame(dallFeaturesNN[id.fold,])
test <- data.frame(dallFeaturesNN[id.cv, ])
train$TV <- as.factor(TV[id.fold])
test$TV <- as.factor(TV[id.cv])
train.hex <- as.h2o(train)
test.hex <- as.h2o(test)
predictors <- 1:(ncol(train.hex)-1)
response <- ncol(train.hex)
print(i)
model <- h2o.deeplearning(x=predictors,
y=response,
training_frame = train.hex,
activation="RectifierWithDropout",
hidden= c(150, 150),
input_dropout_ratio=0.07,
epochs=1,
l1=5e-05,
l2=1e-3,
rho=0.99,
epsilon=1e-8,
stopping_metric = "AUC",
max_w2=5,
reproducible = T,
seed=seed)
preds <- as.data.frame(h2o.predict(model,test.hex))$p1
print(getROC_AUC(preds, TV[id.cv]))
preds.base.train$predict[id.cv] <- preds
}
print(getROC_AUC(preds, TV[id.cv]))
final.res
train.preds <- preds.base.train$predict
final.res <- getROC_AUC(train.preds, TV[train.id])$auc
final.res
head(preds.base.train)
print(seed)
######
# CV #
######
nfolds <- 3
id <- train.id
preds.base.train <- data.frame(predict = rep(0, length(id)), id = id)
head(id)
length(train.id)
final.res <- getROC_AUC(train.preds, TV[train.id])$auc
final.res
id.cv
length(id.cv)
print(getROC_AUC(preds, TV[id.cv]))
print(getROC_AUC(preds, TV[id.cv])$auc)
final.res <- getROC_AUC(train.preds, TV[train.id])$auc
final.res
getROC_AUC((train.preds)[id.cv], (TV[train.id])[id.cv])$auc
preds.base.train <- data.frame(predict = rep(0, length(id)), id = id, TV = 0)
for (i in 1:nfolds) {
id.fold <- which((id %% nfolds + 1) != i)
id.cv <- which((id %% nfolds + 1) == i)
train <- data.frame(dallFeaturesNN[id.fold,])
test <- data.frame(dallFeaturesNN[id.cv, ])
train$TV <- as.factor(TV[id.fold])
test$TV <- as.factor(TV[id.cv])
train.hex <- as.h2o(train)
test.hex <- as.h2o(test)
predictors <- 1:(ncol(train.hex)-1)
response <- ncol(train.hex)
print(i)
model <- h2o.deeplearning(x=predictors,
y=response,
training_frame = train.hex,
activation="RectifierWithDropout",
hidden= c(150, 150),
input_dropout_ratio=0.07,
epochs=1,
l1=5e-05,
l2=1e-3,
rho=0.99,
epsilon=1e-8,
stopping_metric = "AUC",
max_w2=5,
reproducible = T,
seed=seed)
preds <- as.data.frame(h2o.predict(model,test.hex))$p1
print(getROC_AUC(preds, TV[id.cv])$auc)
preds.base.train$predict[id.cv] <- preds
preds.base.train$TV[id.cv] <- TV[id.cv]
}
train.preds <- preds.base.train$predict
final.res <- getROC_AUC(train.preds, TV[train.id])$auc
final.res
dim(preds.base.train)
final.res <- getROC_AUC(preds.base.train$predict,preds.base.train$TV)$auc
final.res
for (scheme in list(c(32, 32), c(64, 64), c(150, 150))) {}
scheme
set.seed(124)
res.list <- list()
for (scheme in list(c(32, 32), c(64, 64), c(150, 150))) {
for (i in 1:nfolds) {
id.fold <- which((id %% nfolds + 1) != i)
id.cv <- which((id %% nfolds + 1) == i)
train <- data.frame(dallFeaturesNN[id.fold,])
test <- data.frame(dallFeaturesNN[id.cv, ])
train$TV <- as.factor(TV[id.fold])
test$TV <- as.factor(TV[id.cv])
train.hex <- as.h2o(train)
test.hex <- as.h2o(test)
predictors <- 1:(ncol(train.hex)-1)
response <- ncol(train.hex)
print(i)
model <- h2o.deeplearning(x=predictors,
y=response,
training_frame = train.hex,
activation="RectifierWithDropout",
hidden= scheme,
input_dropout_ratio=0.07,
epochs=1,
l1=5e-05,
l2=1e-3,
rho=0.99,
epsilon=1e-8,
stopping_metric = "AUC",
max_w2=5,
reproducible = T,
seed=seed)
preds <- as.data.frame(h2o.predict(model,test.hex))$p1
print(getROC_AUC(preds, TV[id.cv])$auc)
preds.base.train$predict[id.cv] <- preds
preds.base.train$TV[id.cv] <- TV[id.cv]
}
train.preds <- preds.base.train$predict
final.res <- getROC_AUC(preds.base.train$predict,preds.base.train$TV)$auc
res.list[[length(res.list) + 1]] <- data.frame(scheme = scheme[1], score = final.res)
}
res.list
1
